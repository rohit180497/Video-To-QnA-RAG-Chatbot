{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from transformers import pipeline\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] += os.pathsep + 'C:/Program Files/ffmpeg/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\workspace\\\\on-campus\\\\data_initiative\\\\task2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = mp.VideoFileClip(\"sample/1676138.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in test/1676138.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/662 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "audio_file = video.audio \n",
    "audio_file.write_audiofile(\"test/1676138.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize recognizer \n",
    "# r = sr.Recognizer() \n",
    "# # Load the audio file \n",
    "# with sr.AudioFile(\"test/1676138.wav\") as source: \n",
    "#     data = r.record(source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMERS MODEL: whisper-small\n",
    "def transcribe_audio(audio_file_path):\n",
    "    transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "    transcription_results = transcriber(audio_file_path)\n",
    "    transcription_text = transcription_results.get('text', \"No transcription results found.\")\n",
    "    \n",
    "#SAVE THE DATE WE MADE THE TRANSCRIPTION\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "# CREATE DATAFRAME TO STORE RESULTS\n",
    "    df = pd.DataFrame({'Current_Date': [current_date],\n",
    "                       'Video_Name': [1676138], \n",
    "                       'Transcription': [transcription_text]})\n",
    "    \n",
    "# PRINT TRANSCRIPTION\n",
    "    print(\"Transcription Results:\", transcription_text) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = os.path.join(\"test\", \"1676138.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription Results:  Quick is very simple. One switch between the two batters on the pitch is a run. But you can get stumped by the wicketkeeper. You can get caught. You can get balled. You can get LBW. You don't want to go LBW. Hit it over the fence. Sixer! Sixer! Home run! No! Sixer! Sixer! If you leave the piece while it's off, silly mid-on can hit the wickets and get you run out. Silly moron. He could be chucking, throwing googly's, yorkers, donkey drops. But you don't want the finger because that means you're out. Out! How's that? How is that? How is he? How are you? Fine.\n",
      "  Current_Date  Video_Name                                      Transcription\n",
      "0   2024-07-12     1676138   Quick is very simple. One switch between the ...\n"
     ]
    }
   ],
   "source": [
    "#SEARCH FOR THE AUDIO IN THE FILE PATH AND EXECUTE TRANSCRIPTION\n",
    "df = transcribe_audio(audio_file_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"ffmpeg -version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current_Date</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-12</td>\n",
       "      <td>1676138</td>\n",
       "      <td>Quick is very simple. One switch between the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Current_Date  Video_Name                                      Transcription\n",
       "0   2024-07-12     1676138   Quick is very simple. One switch between the ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(embeddings, 'embeddings.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
